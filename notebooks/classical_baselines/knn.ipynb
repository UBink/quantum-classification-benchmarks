{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900696c-5fc8-44a1-a407-bd6155aff100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from datetime import datetime\n",
    "\n",
    "path = \"../../data/processed/\"\n",
    "\n",
    "datasets = [\"mnist_01_pca_4\",\n",
    "            \"mnist_01_pca_8\",\n",
    "            \"mnist_38_pca_4\",\n",
    "            \"mnist_38_pca_8\"]\n",
    "\n",
    "# Multiple seeds for timing variation\n",
    "seeds = [42, 100, 20, 5, 99]\n",
    "\n",
    "sample_sizes = [500, 2000, 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38644f37-e48c-47e4-9518-0a9b53e50d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing results or create new\n",
    "results_path = \"../../results/classical_knn_baseline_results.json\"\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    with open(results_path, 'r') as f:\n",
    "        all_results = json.load(f)\n",
    "    print(f\"Loaded existing results with {len(all_results['results'])} entries\")\n",
    "else:\n",
    "    all_results = {\n",
    "        \"experiment_info\": {\n",
    "            \"model_type\": \"classical_knn\",\n",
    "            \"date\": datetime.now().isoformat(),\n",
    "            \"hyperparameter_tuning\": \"GridSearchCV with k=[3, 5, 7, 9, 11, 15]\",\n",
    "            \"cv_folds\": 5\n",
    "        },\n",
    "        \"results\": []\n",
    "    }\n",
    "    print(\"Created new results file\")\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset_path = path + dataset\n",
    "    \n",
    "    X_train_full = np.load(dataset_path + \"/X_train.npy\")\n",
    "    X_test = np.load(dataset_path + \"/X_test.npy\")\n",
    "    y_train_full = np.load(dataset_path + \"/y_train.npy\")\n",
    "    y_test = np.load(dataset_path + \"/y_test.npy\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    print(f\"Available training samples: {X_train_full.shape[0]}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for n_samples in sample_sizes:\n",
    "        existing = [r for r in all_results[\"results\"] \n",
    "                   if r[\"dataset\"] == dataset and r[\"n_train\"] == n_samples]\n",
    "        \n",
    "        if existing and len(existing) >= len(seeds):\n",
    "            print(f\"\\nSkipping {dataset} with {n_samples} samples (already complete)\")\n",
    "            continue\n",
    "        \n",
    "        if n_samples > X_train_full.shape[0]:\n",
    "            print(f\"\\nSkipping {n_samples} samples (only {X_train_full.shape[0]} available)\")\n",
    "            continue\n",
    "        \n",
    "        if n_samples == X_train_full.shape[0]:\n",
    "            X_train, y_train = X_train_full, y_train_full\n",
    "            print(f\"\\n{'─'*70}\")\n",
    "            print(f\"Training with FULL dataset ({n_samples} samples)\")\n",
    "            print(f\"{'─'*70}\")\n",
    "        else:\n",
    "            X_train, _, y_train, _ = train_test_split(\n",
    "                X_train_full, y_train_full,\n",
    "                train_size=n_samples,\n",
    "                random_state=42,\n",
    "                stratify=y_train_full\n",
    "            )\n",
    "            print(f\"\\n{'─'*70}\")\n",
    "            print(f\"Training with {n_samples} samples (subsampled)\")\n",
    "            print(f\"{'─'*70}\")\n",
    "        \n",
    "        for seed in seeds:\n",
    "            specific_existing = [r for r in all_results[\"results\"] \n",
    "                                if r[\"dataset\"] == dataset \n",
    "                                and r[\"n_train\"] == n_samples \n",
    "                                and r.get(\"seed\") == seed]\n",
    "            \n",
    "            if specific_existing:\n",
    "                print(f\"  Seed {seed}: Already exists, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # k-NN with GridSearchCV\n",
    "            param_grid = {'n_neighbors': [3, 5, 7, 9, 11, 15]}\n",
    "            \n",
    "            knn_cv = GridSearchCV(\n",
    "                KNeighborsClassifier(),\n",
    "                param_grid,\n",
    "                cv=5,\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Train (actually just stores data, k-NN is lazy)\n",
    "            start_time = time.time()\n",
    "            knn_cv.fit(X_train, y_train)\n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Inference (this is where k-NN does actual work)\n",
    "            start_time = time.time()\n",
    "            y_pred = knn_cv.predict(X_test)\n",
    "            inference_time = time.time() - start_time\n",
    "            \n",
    "            # Metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            \n",
    "            result = {\n",
    "                \"dataset\": dataset,\n",
    "                \"n_train\": int(n_samples),\n",
    "                \"n_test\": int(X_test.shape[0]),\n",
    "                \"n_features\": int(X_train.shape[1]),\n",
    "                \"seed\": int(seed),\n",
    "                \"best_k\": int(knn_cv.best_params_['n_neighbors']),\n",
    "                \"accuracy\": float(accuracy),\n",
    "                \"f1_score\": float(f1),\n",
    "                \"training_time_seconds\": float(training_time),\n",
    "                \"inference_time_seconds\": float(inference_time),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            all_results[\"results\"].append(result)\n",
    "            \n",
    "            print(f\"  Seed {seed:3d}: Acc={accuracy:.4f}, F1={f1:.4f}, \"\n",
    "                  f\"k={knn_cv.best_params_['n_neighbors']}, \"\n",
    "                  f\"Train={training_time:.3f}s, Infer={inference_time:.3f}s\")\n",
    "\n",
    "os.makedirs(\"../../results\", exist_ok=True)\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(all_results, indent=2, fp=f)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Results saved to {results_path}\")\n",
    "print(f\"Total experiments: {len(all_results['results'])}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f217d-263b-43ad-b9a6-107a876d350a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
