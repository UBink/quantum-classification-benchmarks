{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22ba89ec-6716-42c5-a537-7abb66af45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from datetime import datetime\n",
    "\n",
    "path = \"../../../../data/multiclass/processed/\"\n",
    "\n",
    "datasets = [\"mnist_multi4_pca_4\",\n",
    "            \"mnist_multi4_pca_8\",\n",
    "        ]\n",
    "\n",
    "# Multiple seeds for timing variation\n",
    "seeds = [42, 100, 20, 5, 99]\n",
    "\n",
    "sample_sizes = [100, 250, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4703c95c-90ba-4a9d-9b3a-798aa125b5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing results with 20 entries\n"
     ]
    }
   ],
   "source": [
    "# Load existing results or create new\n",
    "results_path = \"../../../../results/4-way_multi_classical_svm_baseline_results.json\"\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    with open(results_path, 'r') as f:\n",
    "        all_results = json.load(f)\n",
    "    print(f\"Loaded existing results with {len(all_results['results'])} entries\")\n",
    "else:\n",
    "    all_results = {\n",
    "        \"experiment_info\": {\n",
    "            \"model_type\": \"classical_svm_rbf\",\n",
    "            \"date\": datetime.now().isoformat(),\n",
    "            \"hyperparameter_tuning\": \"GridSearchCV with C=[0.1, 1, 10, 100] and gamma=['scale', 'auto', 0.001, 0.01, 0.1]\",\n",
    "            \"cv_folds\": 5\n",
    "        },\n",
    "        \"results\": []\n",
    "    }\n",
    "    print(\"Created new results file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec32115-776f-44bc-8a7c-b23f26f64df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Dataset: mnist_multi4_pca_4\n",
      "Available training samples: 400\n",
      "======================================================================\n",
      "\n",
      " Skipping mnist_multi4_pca_4 with 100 samples (already complete)\n",
      "\n",
      " Skipping mnist_multi4_pca_4 with 250 samples (already complete)\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Training with FULL dataset (400 samples)\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Seed  42: Acc=0.8900, F1=0.8892, C=1, γ=scale, Train=0.06s\n",
      "  Seed 100: Acc=0.8900, F1=0.8892, C=1, γ=scale, Train=0.05s\n",
      "  Seed  20: Acc=0.8900, F1=0.8892, C=1, γ=scale, Train=0.05s\n",
      "  Seed   5: Acc=0.8900, F1=0.8892, C=1, γ=scale, Train=0.07s\n",
      "  Seed  99: Acc=0.8900, F1=0.8892, C=1, γ=scale, Train=0.05s\n",
      "\n",
      "======================================================================\n",
      "Dataset: mnist_multi4_pca_8\n",
      "Available training samples: 400\n",
      "======================================================================\n",
      "\n",
      " Skipping mnist_multi4_pca_8 with 100 samples (already complete)\n",
      "\n",
      " Skipping mnist_multi4_pca_8 with 250 samples (already complete)\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "Training with FULL dataset (400 samples)\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "  Seed  42: Acc=0.9500, F1=0.9501, C=1, γ=auto, Train=0.05s\n",
      "  Seed 100: Acc=0.9500, F1=0.9501, C=1, γ=auto, Train=0.06s\n",
      "  Seed  20: Acc=0.9500, F1=0.9501, C=1, γ=auto, Train=0.07s\n",
      "  Seed   5: Acc=0.9500, F1=0.9501, C=1, γ=auto, Train=0.06s\n",
      "  Seed  99: Acc=0.9500, F1=0.9501, C=1, γ=auto, Train=0.05s\n",
      "\n",
      "======================================================================\n",
      " Results saved to ../../../../results/4-way_multi_classical_svm_baseline_results.json\n",
      "Total experiments: 30\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run experiments\n",
    "for dataset in datasets:\n",
    "    dataset_path = path + dataset\n",
    "    \n",
    "    # Load full training data\n",
    "    X_train_full = np.load(dataset_path + \"/X_train.npy\")\n",
    "    X_test = np.load(dataset_path + \"/X_test.npy\")\n",
    "    y_train_full = np.load(dataset_path + \"/y_train.npy\")\n",
    "    y_test = np.load(dataset_path + \"/y_test.npy\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    print(f\"Available training samples: {X_train_full.shape[0]}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for n_samples in sample_sizes:\n",
    "        # Skip if already exists\n",
    "        existing = [r for r in all_results[\"results\"] \n",
    "                   if r[\"dataset\"] == dataset and r[\"n_train\"] == n_samples]\n",
    "        \n",
    "        if existing and len(existing) >= len(seeds):\n",
    "            print(f\"\\n Skipping {dataset} with {n_samples} samples (already complete)\")\n",
    "            continue\n",
    "        \n",
    "        # Skip if requesting more than available\n",
    "        if n_samples > X_train_full.shape[0]:\n",
    "            print(f\"\\n Skipping {n_samples} samples (only {X_train_full.shape[0]} available)\")\n",
    "            continue\n",
    "        \n",
    "        # Use full dataset or subsample\n",
    "        if n_samples == X_train_full.shape[0]:\n",
    "            X_train, y_train = X_train_full, y_train_full\n",
    "            print(f\"\\n{'─'*70}\")\n",
    "            print(f\"Training with FULL dataset ({n_samples} samples)\")\n",
    "            print(f\"{'─'*70}\")\n",
    "        else:\n",
    "            X_train, _, y_train, _ = train_test_split(\n",
    "                X_train_full, y_train_full,\n",
    "                train_size=n_samples,\n",
    "                random_state=42,  # Fixed for consistency across runs\n",
    "                stratify=y_train_full\n",
    "            )\n",
    "            print(f\"\\n{'─'*70}\")\n",
    "            print(f\"Training with {n_samples} samples (subsampled)\")\n",
    "            print(f\"{'─'*70}\")\n",
    "        \n",
    "        # Run with different seeds\n",
    "        for seed in seeds:\n",
    "            # Check if this specific experiment exists\n",
    "            specific_existing = [r for r in all_results[\"results\"] \n",
    "                                if r[\"dataset\"] == dataset \n",
    "                                and r[\"n_train\"] == n_samples \n",
    "                                and r.get(\"seed\") == seed]\n",
    "            \n",
    "            if specific_existing:\n",
    "                print(f\"  Seed {seed}: Already exists, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Hyperparameter tuning with GridSearchCV\n",
    "            param_grid = {\n",
    "                'C': [0.1, 1, 10, 100],\n",
    "                'gamma': ['scale', 'auto', 0.001, 0.01, 0.1]\n",
    "            }\n",
    "            \n",
    "            svc_cv = GridSearchCV(\n",
    "                SVC(kernel='rbf', random_state=seed),\n",
    "                param_grid,\n",
    "                cv=5,\n",
    "                n_jobs=-1,  # Use all CPU cores\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Train\n",
    "            start_time = time.time()\n",
    "            svc_cv.fit(X_train, y_train)\n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Inference\n",
    "            start_time = time.time()\n",
    "            y_pred = svc_cv.predict(X_test)\n",
    "            inference_time = time.time() - start_time\n",
    "            \n",
    "            # Metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            \n",
    "            # Store result\n",
    "            result = {\n",
    "                \"dataset\": dataset,\n",
    "                \"n_train\": int(n_samples),\n",
    "                \"n_test\": int(X_test.shape[0]),\n",
    "                \"n_features\": int(X_train.shape[1]),\n",
    "                \"seed\": int(seed),\n",
    "                \"best_C\": float(svc_cv.best_params_['C']),\n",
    "                \"best_gamma\": float(svc_cv.best_params_['gamma']) if isinstance(svc_cv.best_params_['gamma'], (int, float)) else str(svc_cv.best_params_['gamma']),\n",
    "                \"accuracy\": float(accuracy),\n",
    "                \"f1_score\": float(f1),\n",
    "                \"training_time_seconds\": float(training_time),\n",
    "                \"inference_time_seconds\": float(inference_time),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            all_results[\"results\"].append(result)\n",
    "            \n",
    "            print(f\"  Seed {seed:3d}: Acc={accuracy:.4f}, F1={f1:.4f}, \"\n",
    "                  f\"C={svc_cv.best_params_['C']}, γ={svc_cv.best_params_['gamma']}, \"\n",
    "                  f\"Train={training_time:.2f}s\")\n",
    "\n",
    "# Save results\n",
    "os.makedirs(\"../../../../results\", exist_ok=True)\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(all_results, indent=2, fp=f)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\" Results saved to {results_path}\")\n",
    "print(f\"Total experiments: {len(all_results['results'])}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ee8d2-582f-4bd5-9b62-08c47be358f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qml-env)",
   "language": "python",
   "name": "qml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
